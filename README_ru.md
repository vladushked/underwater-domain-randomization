# Использование синтетических данных при обучении глубоких нейронных сетей для распознавания подводных объектов в реальном мире

Vladislav A. Plotnikov
plotnikovva@student.bmstu.ru
vladislav.a.plotnikov@yandex.ru

Yaroslav M. Kamenev
kamenev.yar@gmail.com

Vladimir V. Serebrenny
vsereb@bmstu.ru

**Abstract.** Конволюционные нейронные сети широко используются для решения задачи распознавания объектов на изображениях и имеют много преимуществ перед классическими алгоритмами обработки изображений. Однако для обучения таких нейронных сетей требуется большой набор данных, сбор и маркировка которых занимает много времени, особенно для подводных объектов. Сбор данных под водой предполагает полномасштабные поездки в бассейн или на открытую воду и требует водонепроницаемого оборудования. В данной статье рассматривается использование компьютерного симулятора и рандомизации домена, а также применение генеративной нейронной сети для сбора данных и их использования при обучении сверточных нейронных сетей для распознавания подводных объектов. Виртуальный симулятор, построенный на движке Unity, использовался для визуализации подводных сцен с различным положением камеры и подводных объектов, визуальных эффектов, а также различных текстур и объектов. Генеративная нейронная сеть CycleGAN использовалась для преобразования синтетических данных в "реальную" форму. Авторы статьи подготовили несколько наборов данных, содержащих реальные, полусинтетические и полностью синтетические изображения, которые были использованы для обучения сверточной нейронной сети YOLOv5, и сравнили качество распознавания объектов на валидационном наборе, состоящем из реальных данных. Для обучения были выбраны объекты из заданий соревнований по подводной робототехнике SAUVC.

**Keywords.** *Сверточные нейронные сети, распознавание объектов, подводная робототехника, рандомизация доменов, CycleGAN, YOLOv5*

## Введение

Нейросети часто применяются для задачи распознавания объектов под водой и имеют множество преимуществ перед классическими алгоритмами обработки изображений [https://www.researchgate.net/publication/360196795_Classical_and_neural_network_approaches_to_object_detection_in_underwater_robotics_competitions, https://www.researchgate.net/publication/339465579_Underwater_Object_Detection_and_Tracking , https://www.researchgate.net/publication/359195058_Underwater_object_detection_architectures_and_algorithms_-_a_comprehensive_review , https://www.researchgate.net/publication/359547226_A_Survey_on_Underwater_Object_Detection]. Однако обучение таких нейросетей требует большого набора данных, сбор и разметка которых занимают много времени, особенно для подводных объектв. Процесс сбора данных требует неоднократных выездов в бассейн или на открытую воду, что не всегда возможно. 

Применение симулятора может значительно уменьшить затраты на сбор данных, сбор и разметка изображений будут выполняться автоматически. Однако, симуляционная среда не сможет полностью имитировать реальные условия и обученная на симуляции нейросеть не будет работать в реальном мире с приемлемым качеством. Такая проблема носит название reality-gap [Object Detection using Domain Randomization and Generative Adversarial Refinement of Synthetic Images].

Cуществует несколько подходов для уменьшения reality-gap. Первый подход - domain randomization для сцены в симуляторе. При этом можно рандомизировать несколько параметров сцены, например, цвет объектов, текстуры, освещение и т.д. Такой подход сильно разнообразит обучающие данные, что позволит обучить нейросеть выделять общие признаки объекта не привязываясь к особенностям отображения в симуляции, что позволит значительно увеличить качество распознавания уже в реальном мире.

Второй подход основан на улучшении синтетических изображений. Для этого применяются генеративно состязательные нейросети, такие как CycleGAN [Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks] и Pix2Pix [Image-to-Image Translation with Conditional Adversarial Networks]. Они позволяют преобразовывать синтетические изображения в реальные и наоборот. 

В этой статье рассматривается задача распознавания подводных объектов с соревнований по автономной подводной робототехнике SAUVC в Сингапуре [https://www.researchgate.net/publication/360196795_Classical_and_neural_network_approaches_to_object_detection_in_underwater_robotics_competitions]. Нейросеть YOLOv5 [YOLOv5: Training Object Detection Models at Scale] была использована для реализации распознавания и сравнения приведенных выше методов уменьшения reality-gap.

Данная работа имеет следующую структуру: в следующем разделе приведено описание обучения эталонной модели на реальных данных, далее описан процесс сбора синтетических данных, далее в разделах описано применение методов domain randomization и улучшения изображений с помощью GAN для уменьшения reality-gap, после этого приведены результаты обучения на синтетических и полусинтетических данных и проведено сравнение методов с обучением на реальных данных. В заключительном разделе приведено краткое изложение полученных результатов и выводов.

## Генерация синтетических данных с использованием рандомизации сцены

Соревнования SAUVC проходят в стандартном плавательном бассейне с максимальной глубиной 2 метра, в котором робот должен выполнить ряд заданий, взаимодействуя с различными подводными объектами. Положение всех объектов на дне определено правилами соревнований, при этом некоторые объекты могут передвинуть в начале каждой попытки выполнения. В целом можно выделить 7 классов объектов:
    
* 1 - gate
* 2 - red_flare
* 3 - yellow_flare
* 4 - red_bowl
* 5 - blue_bowl
* 6 - mat
* 7 - gate_qualification 

Для генерации синтетических данных была смоделирована сцена в симуляторе Unity, максимально приближенно повторяющая реальный бассейн с объектами. Для этого были сделаны 3d модели плавательного бассейна и необходимых объектов, которые затем были расположены в соответствии с правилами соревнований.

Автоматический сбор синтетических данных был реализован с помощью скрипта, который выполняет рандомизацию сцены, затем генерирует прямоугольные bbox для каждого объекта, попадающего в кадр, а после этого сохраняет изображение и аннотации в формате YOLO. 

Скрипт позволяет рандомизировать следующие параметры: 

  * Положение камеры
  * Положение, цвета и текстуры объектов
  * Положение и цвет источников света
  * Наличие, интенсивность и цвет тумана   

![View of underwater scene from Unity Editor](/images/dataset/scene.png)
View of underwater scene from Unity Editor

Для исследования влияния рандомизации на качество распознавания было собрано 4 датасета с разными уровнями рандомизации сцены:

1. **round_1** - рандомизация тумана и положения камеры;
2. **round_2** - round_1 с рандомизированными текстурами подводного подводных обхектов;
3. **round_3** - раунд_1 с рандомизированными текстурами бассейна;
4. **round_0** - раунд_1 и рандомизация текстур всех объектов и бассейна;

На всех изображениях объект находится в центре кадра. 

Всего было собрано по 500 синтетических изображений для каждого из датасетов. 

![Examples of one image in 4 rounds, clockwise: round_1 (upper left corner), round_2, round_0, round_3](/images/dataset/examples.png)
Examples of one image in 4 rounds, clockwise: round_1 (upper left corner), round_2, round_0, round_3

### Обучение на реальных данных

Neural net: YOLOv5m

Параметры обучения:
- GPU: Nvidia Quadro P4000
- framework: PyTorch 
- 869 images total: 732 in train set, 137 in validation set;
- image size: 640x640
- 300 epochs
- batch size - 16
- data augmentation

![Train batch](/images/training_real/batch.png)
Train batch

![Metrics](/images/training_real/graphs.png)
Metrics

![Validaton on real data](/images/training_real/val.png)
Validaton on real data